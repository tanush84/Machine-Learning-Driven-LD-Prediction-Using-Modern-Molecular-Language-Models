{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae814b94-ce82-4cad-acb7-5e227d5fc1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from transformers import AutoModel, AutoTokenizer, AutoConfig\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoConfig,\n",
    "    AutoModelForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "CHEMBERT_NAME = \"seyonec/ChemBERTa-zinc-base-v1\"\n",
    "# Tokenizer\n",
    "\n",
    "def tokenize(batch):\n",
    "    return tokenizer(\n",
    "        batch[\"smiles\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=160\n",
    "    )\n",
    "\n",
    "# or DeepChem/ChemBERTa-77M-MLM\n",
    "tokenizer = AutoTokenizer.from_pretrained(CHEMBERT_NAME)\n",
    "config = AutoConfig.from_pretrained(CHEMBERT_NAME,output_hidden_states=True)\n",
    "encoder = AutoModel.from_pretrained(CHEMBERT_NAME,config=config)\n",
    "\n",
    "df_train = pd.read_csv('./NIHDataset/train_df.csv')\n",
    "df_val   = pd.read_csv('./NIHDataset/val_df.csv')\n",
    "df_test  = pd.read_csv('./NIHDataset/test_df.csv')\n",
    "\n",
    "df_train = df_train.rename(columns={\"SMILES_CANON\": \"smiles\", \"logLD50\": \"LD50\"})\n",
    "df_val   = df_val.rename(columns={\"SMILES_CANON\": \"smiles\", \"logLD50\": \"LD50\"})\n",
    "df_test  = df_test.rename(columns={\"SMILES_CANON\": \"smiles\", \"logLD50\": \"LD50\"})\n",
    "\n",
    "df_train = df_train[['smiles', 'LD50']].dropna()\n",
    "df_val   = df_val[['smiles', 'LD50']].dropna()\n",
    "df_test  = df_test[['smiles', 'LD50']].dropna()\n",
    "print(len(df_train), len(df_val), len(df_test))\n",
    "train_ds = Dataset.from_pandas(df_train.reset_index(drop=True))\n",
    "val_ds   = Dataset.from_pandas(df_val.reset_index(drop=True))\n",
    "test_ds  = Dataset.from_pandas(df_test.reset_index(drop=True))\n",
    "\n",
    "train_ds = train_ds.map(tokenize, batched=True)\n",
    "val_ds   = val_ds.map(tokenize, batched=True)\n",
    "test_ds  = test_ds.map(tokenize, batched=True)\n",
    "\n",
    "train_ds = train_ds.rename_column(\"LD50\", \"labels\")\n",
    "val_ds   = val_ds.rename_column(\"LD50\", \"labels\")\n",
    "test_ds  = test_ds.rename_column(\"LD50\", \"labels\")\n",
    "\n",
    "cols = [\"input_ids\", \"attention_mask\", \"labels\"]\n",
    "train_ds.set_format(\"torch\", columns=cols)\n",
    "val_ds.set_format(\"torch\", columns=cols)\n",
    "test_ds.set_format(\"torch\", columns=cols)\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    preds, labels = eval_pred\n",
    "    preds = preds.squeeze()\n",
    "\n",
    "    mse = mean_squared_error(labels, preds)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(labels, preds)\n",
    "    r2 = r2_score(labels, preds)\n",
    "\n",
    "    return {\n",
    "        \"MSE\": mse,\n",
    "        \"RMSE\": rmse,\n",
    "        \"MAE\": mae,\n",
    "        \"R2\": r2\n",
    "    }\n",
    "def pool_hidden_states(outputs, attention_mask, mode=\"cls\"):\n",
    "    hidden_states = outputs.hidden_states\n",
    "\n",
    "    if mode == \"cls\":\n",
    "        return hidden_states[-1][:, 0]\n",
    "\n",
    "    elif mode == \"mean\":\n",
    "        last = hidden_states[-1]\n",
    "        mask = attention_mask.unsqueeze(-1)\n",
    "        return (last * mask).sum(1) / mask.sum(1)\n",
    "\n",
    "    else:\n",
    "        raise ValueError\n",
    "class RegressionHead(nn.Module):\n",
    "    def __init__(self, hidden_dim, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "class ChemBERTRegressor(nn.Module):\n",
    "    def __init__(self, encoder, pooling=\"cls\"):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.pooling = pooling\n",
    "        self.regressor = RegressionHead(\n",
    "            hidden_dim=encoder.config.hidden_size\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        outputs = self.encoder(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask\n",
    "        )\n",
    "\n",
    "        pooled = pool_hidden_states(\n",
    "            outputs, attention_mask, self.pooling\n",
    "        )\n",
    "\n",
    "        preds = self.regressor(pooled).squeeze(-1)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss = nn.MSELoss()(preds, labels)\n",
    "\n",
    "        return {\"loss\": loss, \"logits\": preds}\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./chembert_ld50\",\n",
    "    eval_strategy=\"epoch\",   # FIXED\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=100,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=100,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"RMSE\",\n",
    "    greater_is_better=False,\n",
    "    fp16=torch.cuda.is_available(),\n",
    "    report_to=\"none\"\n",
    ")\n",
    "model = ChemBERTRegressor(\n",
    "    encoder=encoder,\n",
    "    pooling=\"cls\"   # SAME as ModernBERT\n",
    ")\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=val_ds,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "trainer.train()\n",
    "# ---- External test evaluation ----\n",
    "test_outputs = trainer.predict(test_ds)\n",
    "\n",
    "# Raw predictions & labels\n",
    "test_preds  = test_outputs.predictions.squeeze()\n",
    "test_labels = test_outputs.label_ids\n",
    "\n",
    "# ---- Metrics ----\n",
    "test_mse  = mean_squared_error(test_labels, test_preds)\n",
    "test_rmse = np.sqrt(test_mse)\n",
    "test_mae  = mean_absolute_error(test_labels, test_preds)\n",
    "test_r2   = r2_score(test_labels, test_preds)\n",
    "\n",
    "print(\"\\n===== External Test Performance (ChemBERT) =====\")\n",
    "print(f\"MAE  : {test_mae:.4f}\")\n",
    "print(f\"RMSE : {test_rmse:.4f}\")\n",
    "print(f\"R2   : {test_r2:.4f}\")\n",
    "print(f\"MSE  : {test_mse:.4f}\")\n",
    "# Save predictions\n",
    "test_results = pd.DataFrame({\n",
    "    \"SMILES\": df_test[\"smiles\"].values,\n",
    "    \"True_LD50\": test_labels,\n",
    "    \"Pred_LD50\": test_preds\n",
    "})\n",
    "\n",
    "\n",
    "def plot_with_metrics(df, true_col=\"True_LD50\", pred_col=\"Pred_LD50\"):\n",
    "    \n",
    "    y_true = df[true_col].values\n",
    "    y_pred = df[pred_col].values\n",
    "\n",
    "    # ---- Metrics ----\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "    # ---- Fold errors ----\n",
    "    fold_error = np.maximum(y_pred/y_true, y_true/y_pred)\n",
    "\n",
    "    within_2fold = np.mean(fold_error <= 2) * 100\n",
    "    within_3fold = np.mean(fold_error <= 3) * 100\n",
    "\n",
    "    # ---- Plot ----\n",
    "    min_val = min(y_true.min(), y_pred.min())\n",
    "    max_val = max(y_true.max(), y_pred.max())\n",
    "    x = np.linspace(min_val, max_val, 100)\n",
    "\n",
    "    plt.figure(figsize=(7,7))\n",
    "\n",
    "    plt.scatter(y_true, y_pred, alpha=0.7)\n",
    "\n",
    "    # Ideal\n",
    "    plt.plot(x, x, linestyle='--', linewidth=2, label=\"Ideal (y=x)\")\n",
    "\n",
    "    # 2-fold\n",
    "    plt.plot(x, 2*x, linestyle=':', linewidth=2, label=\"±2-fold\")\n",
    "    plt.plot(x, x/2, linestyle=':', linewidth=2)\n",
    "\n",
    "    # 3-fold\n",
    "    plt.plot(x, 3*x, linestyle='-.', linewidth=2, label=\"±3-fold\")\n",
    "    plt.plot(x, x/3, linestyle='-.', linewidth=2)\n",
    "\n",
    "    # ---- Text box ----\n",
    "    textstr = (\n",
    "        f\"R² = {r2:.3f}\\n\"\n",
    "        f\"MAE = {mae:.3f}\\n\"\n",
    "        f\"RMSE = {rmse:.3f}\\n\\n\"\n",
    "        f\"Within 2-fold = {within_2fold:.1f}%\\n\"\n",
    "        f\"Within 3-fold = {within_3fold:.1f}%\"\n",
    "    )\n",
    "\n",
    "    plt.text(0.05, 0.95, textstr,\n",
    "             transform=plt.gca().transAxes,\n",
    "             fontsize=11,\n",
    "             verticalalignment='top',\n",
    "             bbox=dict(boxstyle=\"round\", alpha=0.2))\n",
    "\n",
    "    plt.xlabel(\"Actual LD50\", fontsize=14)\n",
    "    plt.ylabel(\"Predicted LD50\", fontsize=14)\n",
    "    plt.title(\"Prediction vs Actual (Test Set)\", fontsize=16)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    # Print metrics also\n",
    "    print(\"R²:\", r2)\n",
    "    print(\"MAE:\", mae)\n",
    "    print(\"RMSE:\", rmse)\n",
    "    print(\"Within 2-fold (%):\", within_2fold)\n",
    "    print(\"Within 3-fold (%):\", within_3fold)\n",
    "    \n",
    "plot_with_metrics(test_results,true_col=\"True_LD50\",pred_col=\"Pred_LD50\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
