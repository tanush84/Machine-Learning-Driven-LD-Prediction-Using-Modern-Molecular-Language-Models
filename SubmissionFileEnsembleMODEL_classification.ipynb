{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2947702-4c70-410b-abbb-8997719ad295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¹ Computing RDKit descriptors...\n",
      "âœ… Selected 97 descriptors with |r| â‰¥ 0.05\n",
      "âœ… Final feature shapes:\n",
      "Train: (7117, 97)\n",
      "Val  : (890, 97)\n",
      "Test : (890, 97)\n",
      "\n",
      "ðŸš€ Training base models...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import GradientBoostingClassifier, HistGradientBoostingClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem.Scaffolds import MurckoScaffold\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from rdkit.Chem.Scaffolds import MurckoScaffold\n",
    "from sklearn.ensemble import GradientBoostingClassifier, HistGradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, matthews_corrcoef, classification_report, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import os\n",
    "import joblib\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from rdkit.Chem import Descriptors\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import pearsonr\n",
    "DESC_NAMES = [name for name, _ in Descriptors.descList]\n",
    "\n",
    "def compute_rdkit_descriptors(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        return [np.nan] * len(DESC_NAMES)\n",
    "    return [func(mol) for _, func in Descriptors.descList]\n",
    "\n",
    "\n",
    "def compute_descriptor_df(df, smiles_col=\"smiles\"):\n",
    "    desc_values = df[smiles_col].apply(compute_rdkit_descriptors)\n",
    "    desc_df = pd.DataFrame(desc_values.tolist(), columns=DESC_NAMES)\n",
    "    return desc_df\n",
    "def select_correlated_descriptors(X, y, threshold=0.05, min_samples=30):\n",
    "    \"\"\"\n",
    "    Select descriptors with |Pearson r| >= threshold using pairwise complete data.\n",
    "    \"\"\"\n",
    "    selected = []\n",
    "    correlations = {}\n",
    "\n",
    "    y = np.asarray(y)\n",
    "\n",
    "    for col in X.columns:\n",
    "        x = X[col].values\n",
    "\n",
    "        # Mask valid pairs\n",
    "        mask = np.isfinite(x) & np.isfinite(y)\n",
    "\n",
    "        if mask.sum() < min_samples:\n",
    "            continue\n",
    "\n",
    "        x_valid = x[mask]\n",
    "        y_valid = y[mask]\n",
    "\n",
    "        # Skip zero-variance descriptors\n",
    "        if np.std(x_valid) == 0:\n",
    "            continue\n",
    "\n",
    "        r, _ = pearsonr(x_valid, y_valid)\n",
    "\n",
    "        if np.isfinite(r) and abs(r) >= threshold:\n",
    "            selected.append(col)\n",
    "            correlations[col] = r\n",
    "\n",
    "    print(f\"âœ… Selected {len(selected)} descriptors with |r| â‰¥ {threshold}\")\n",
    "    return selected, pd.Series(correlations).sort_values(key=np.abs, ascending=False)\n",
    "gb_model = GradientBoostingClassifier(\n",
    "    n_estimators=300,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=3,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "hgb_model = HistGradientBoostingClassifier(\n",
    "    max_iter=300,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=6,\n",
    "    random_state=42\n",
    ")\n",
    "df_train = pd.read_csv('./NIHDataset/train_df_class.csv')\n",
    "df_test = pd.read_csv('./NIHDataset/test_df_class.csv')\n",
    "df_val = pd.read_csv('./NIHDataset/val_df_class.csv')\n",
    "\n",
    "df_train = df_train.rename(columns={\"LD50_class\": \"label\"})\n",
    "df_val   = df_val.rename(columns={\"LD50_class\": \"label\"})\n",
    "df_test  = df_test.rename(columns={\"LD50_class\": \"label\"})\n",
    "\n",
    "df_train = df_train[['smiles', 'label']].dropna()\n",
    "df_val   = df_val[['smiles', 'label']].dropna()\n",
    "df_test  = df_test[['smiles', 'label']].dropna()\n",
    "\n",
    "print(\"ðŸ”¹ Computing RDKit descriptors...\")\n",
    "X_train_desc = compute_descriptor_df(df_train)\n",
    "X_val_desc   = compute_descriptor_df(df_val)\n",
    "X_test_desc  = compute_descriptor_df(df_test)\n",
    "\n",
    "y_train = df_train[\"label\"].values\n",
    "y_val   = df_val[\"label\"].values\n",
    "y_test  = df_test[\"label\"].values\n",
    "\n",
    "selected_desc, corr_series = select_correlated_descriptors(X_train_desc,y_train,threshold=0.05)\n",
    "\n",
    "X_train_sel = X_train_desc[selected_desc]\n",
    "X_val_sel   = X_val_desc[selected_desc]\n",
    "X_test_sel  = X_test_desc[selected_desc]\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=5, weights=\"distance\")\n",
    "\n",
    "X_train_imp = imputer.fit_transform(X_train_sel)\n",
    "X_val_imp   = imputer.transform(X_val_sel)\n",
    "X_test_imp  = imputer.transform(X_test_sel)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train_imp)\n",
    "X_val   = scaler.transform(X_val_imp)\n",
    "X_test  = scaler.transform(X_test_imp)\n",
    "\n",
    "print(\"âœ… Final feature shapes:\")\n",
    "print(\"Train:\", X_train.shape)\n",
    "print(\"Val  :\", X_val.shape)\n",
    "print(\"Test :\", X_test.shape)\n",
    "\n",
    "\n",
    "print(\"\\nðŸš€ Training base models...\")\n",
    "\n",
    "gb_model.fit(X_train, y_train)\n",
    "hgb_model.fit(X_train, y_train)\n",
    "val_pred_gb  = gb_model.predict(X_val)\n",
    "val_pred_hgb = hgb_model.predict(X_val)\n",
    "\n",
    "val_prob_gb  = gb_model.predict_proba(X_val)\n",
    "val_prob_hgb = hgb_model.predict_proba(X_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "163aa98b-5c74-4760-a46d-38fd5c63adb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GradientBoosting\n",
      "ACC : 0.648314606741573\n",
      "F1  : 0.4878039013569899\n",
      "MCC : 0.3598138917176483\n",
      "\n",
      "HistGradientBoosting\n",
      "ACC : 0.6550561797752809\n",
      "F1  : 0.5404026705844274\n",
      "MCC : 0.3868917994865379\n",
      "\n",
      "ðŸ“Š Ensemble Weights:\n",
      "GB  : 0.4818684201233139\n",
      "HGB : 0.518131579876686\n",
      "\n",
      "================ FINAL TEST PERFORMANCE ================\n",
      "Accuracy: 0.6393258426966292\n",
      "F1 macro: 0.4852115485239922\n",
      "MCC: 0.329954952428251\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 31  14  25   0]\n",
      " [ 12  54 124   1]\n",
      " [  5  32 462   9]\n",
      " [  0   3  96  22]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6458    0.4429    0.5254        70\n",
      "           1     0.5243    0.2827    0.3673       191\n",
      "           2     0.6535    0.9094    0.7605       508\n",
      "           3     0.6875    0.1818    0.2876       121\n",
      "\n",
      "    accuracy                         0.6393       890\n",
      "   macro avg     0.6278    0.4542    0.4852       890\n",
      "weighted avg     0.6298    0.6393    0.5933       890\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def evaluate(y_true, y_pred, name):\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    f1  = f1_score(y_true, y_pred, average=\"macro\")\n",
    "    mcc = matthews_corrcoef(y_true, y_pred)\n",
    "    print(f\"\\n{name}\")\n",
    "    print(\"ACC :\", acc)\n",
    "    print(\"F1  :\", f1)\n",
    "    print(\"MCC :\", mcc)\n",
    "    return mcc\n",
    "\n",
    "mcc_gb  = evaluate(y_val, val_pred_gb,  \"GradientBoosting\")\n",
    "mcc_hgb = evaluate(y_val, val_pred_hgb, \"HistGradientBoosting\")\n",
    "\n",
    "weights = np.array([mcc_gb, mcc_hgb])\n",
    "weights = np.clip(weights, 0, None)  # remove negative weights\n",
    "weights = weights / weights.sum()\n",
    "\n",
    "print(\"\\nðŸ“Š Ensemble Weights:\")\n",
    "print(\"GB  :\", weights[0])\n",
    "print(\"HGB :\", weights[1])\n",
    "\n",
    "prob_gb  = gb_model.predict_proba(X_test)\n",
    "prob_hgb = hgb_model.predict_proba(X_test)\n",
    "\n",
    "ensemble_probs = (\n",
    "    weights[0] * prob_gb +\n",
    "    weights[1] * prob_hgb\n",
    ")\n",
    "\n",
    "ensemble_preds = np.argmax(ensemble_probs, axis=1)\n",
    "\n",
    "print(\"\\n================ FINAL TEST PERFORMANCE ================\")\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, ensemble_preds))\n",
    "print(\"F1 macro:\", f1_score(y_test, ensemble_preds, average=\"macro\"))\n",
    "print(\"MCC:\", matthews_corrcoef(y_test, ensemble_preds))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, ensemble_preds))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, ensemble_preds, digits=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e387396-16fd-4621-813f-38d5c5394eec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
